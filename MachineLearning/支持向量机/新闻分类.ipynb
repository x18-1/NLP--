{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                          title label\n0   持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空    国际\n1  COP15专访｜穿汉服的中国代表团成员讲述谈判背后的故事    国际\n2       泰国一艘军舰沉没，搜救队正在寻找33名失踪船员    国际\n3    圆桌｜威斯特伐利亚体系从未退场？俄乌冲突下的欧洲之变    国际\n4  法国败北马克龙表态：决赛不是提前写好的剧本，希望德尚留任    国际",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COP15专访｜穿汉服的中国代表团成员讲述谈判背后的故事</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>泰国一艘军舰沉没，搜救队正在寻找33名失踪船员</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>圆桌｜威斯特伐利亚体系从未退场？俄乌冲突下的欧洲之变</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>法国败北马克龙表态：决赛不是提前写好的剧本，希望德尚留任</td>\n      <td>国际</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('./train2.csv')\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空\n"
     ]
    }
   ],
   "source": [
    "content = df_news.title.values.tolist()\n",
    "print (content[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数据进行结巴分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['夜读', '｜', '照亮', '梅西', '的', '光', '，', '究竟', '来自', '何处', '？']\n"
     ]
    }
   ],
   "source": [
    "# 训练集使用结巴分词\n",
    "content_S = []\n",
    "for line in content:\n",
    "    current_segment = jieba.lcut(line)\n",
    "    if len(current_segment) > 1 and current_segment != '\\r\\n': #换行符\n",
    "        content_S.append(current_segment)\n",
    "print(content_S[1000]) #(list of list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           content_S\n",
      "0  [持续, 追踪, 丨, 俄, 再度, 炮击, 赫尔松, ，, 泽, 连斯基, 呼吁, 西方,...\n",
      "1  [COP15, 专访, ｜, 穿, 汉服, 的, 中国, 代表团, 成员, 讲述, 谈判, ...\n",
      "2  [泰国, 一艘, 军舰, 沉没, ，, 搜救, 队, 正在, 寻找, 33, 名, 失踪, 船员]\n",
      "3  [圆桌, ｜, 威, 斯特伐, 利亚, 体系, 从未, 退场, ？, 俄乌, 冲突, 下, ...\n",
      "4  [法国, 败北, 马克, 龙, 表态, ：, 决赛, 不是, 提前, 写, 好, 的, 剧本...\n"
     ]
    }
   ],
   "source": [
    "# 格式转化\n",
    "df_content = pd.DataFrame({'content_S':content_S})\n",
    "print(df_content.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除数据停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  stopword\n0        丨\n1        ｜\n2        ｜\n3      ———\n4      》），",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stopword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>丨</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>｜</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>｜</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>———</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>》），</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取查看停用词表\n",
    "\n",
    "stopwords = pd.read_csv(\"./hit_stopwords.txt\",index_col=False,sep=\"\\t\",quoting=3,names=['stopword'], encoding='utf-8') #list\n",
    "stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对训练集进行停用词处理\n",
    "\n",
    "# 停用词函数\n",
    "def drop_stopwords(contents, stopwords):\n",
    "    contents_clean = []\n",
    "    all_words = []\n",
    "    for line in contents:\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)\n",
    "            all_words.append(str(word))\n",
    "        contents_clean.append(line_clean)\n",
    "    return contents_clean, all_words\n",
    "    # print (contents_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      contents_clean\n",
      "0  [持续, 追踪, 俄, 再度, 炮击, 赫尔松, 泽, 连斯基, 呼吁, 西方, 加强, 乌...\n",
      "1    [COP15, 专访, 穿, 汉服, 中国, 代表团, 成员, 讲述, 谈判, 背后, 故事]\n",
      "2     [泰国, 一艘, 军舰, 沉没, 搜救, 队, 正在, 寻找, 33, 名, 失踪, 船员]\n",
      "3    [圆桌, 威, 斯特伐, 利亚, 体系, 从未, 退场, 俄乌, 冲突, 下, 欧洲, 之变]\n",
      "4  [法国, 败北, 马克, 龙, 表态, 决赛, 不是, 提前, 写, 好, 剧本, 希望, ...\n",
      "\n",
      "  all_words\n",
      "0        持续\n",
      "1        追踪\n",
      "2         俄\n",
      "3        再度\n",
      "4        炮击\n"
     ]
    }
   ],
   "source": [
    "### 对训练集进行停用词转化 \n",
    "\n",
    "# 对训练集的值进行转化\n",
    "contents = df_content.content_S.values.tolist()\n",
    "\n",
    "# 对停用词进行转化\n",
    "stopwords = stopwords.stopword.values.tolist()\n",
    "\n",
    "# 使用停用词\n",
    "contents_clean, all_words = drop_stopwords(contents, stopwords) \n",
    "\n",
    "# 每一列的分词\n",
    "df_content = pd.DataFrame({'contents_clean':contents_clean})\n",
    "print(df_content.head())\n",
    "\n",
    "print()\n",
    "\n",
    "# 所有词语\n",
    "df_all_words = pd.DataFrame({'all_words':all_words})\n",
    "print(df_all_words.head())\n",
    "\n",
    "###转化结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                       title label\n0                持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空    国际\n1               COP15专访｜穿汉服的中国代表团成员讲述谈判背后的故事    国际\n2                    泰国一艘军舰沉没，搜救队正在寻找33名失踪船员    国际\n3                 圆桌｜威斯特伐利亚体系从未退场？俄乌冲突下的欧洲之变    国际\n4               法国败北马克龙表态：决赛不是提前写好的剧本，希望德尚留任    国际\n...                                      ...   ...\n4995      北京第四批次6宗住宅用地收金135亿元，“热度达到了较高水平”地产界    财经\n4996     杭州第四批次供地：8宗宅地收金98.9亿元，其中3宗达到上限价格地产界    财经\n4997  独家｜知情人谈张核子和核酸生意：深圳坐拥带停机坪别墅，张姗姗是谁？10%公司    财经\n4998       放量大涨沪指收复60日均线，反弹持续性如何？或挑战半年线牛市点线面    财经\n4999      三天涨了超30%！翰宇药业：预防新冠多肽鼻喷已紧急发往多地10%公司    财经\n\n[5000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COP15专访｜穿汉服的中国代表团成员讲述谈判背后的故事</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>泰国一艘军舰沉没，搜救队正在寻找33名失踪船员</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>圆桌｜威斯特伐利亚体系从未退场？俄乌冲突下的欧洲之变</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>法国败北马克龙表态：决赛不是提前写好的剧本，希望德尚留任</td>\n      <td>国际</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>北京第四批次6宗住宅用地收金135亿元，“热度达到了较高水平”地产界</td>\n      <td>财经</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>杭州第四批次供地：8宗宅地收金98.9亿元，其中3宗达到上限价格地产界</td>\n      <td>财经</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>独家｜知情人谈张核子和核酸生意：深圳坐拥带停机坪别墅，张姗姗是谁？10%公司</td>\n      <td>财经</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>放量大涨沪指收复60日均线，反弹持续性如何？或挑战半年线牛市点线面</td>\n      <td>财经</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>三天涨了超30%！翰宇药业：预防新冠多肽鼻喷已紧急发往多地10%公司</td>\n      <td>财经</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "持续追踪丨俄再度炮击赫尔松，泽连斯基呼吁西方加强乌防空\n",
      "赫尔松  连斯基  炮击  追踪  呼吁\n"
     ]
    }
   ],
   "source": [
    "# 提取关键词\n",
    "import jieba.analyse\n",
    "index = 0\n",
    "\n",
    "\n",
    "print (df_news['title'][index])\n",
    "content_S_str = \"\".join(content_S[index])\n",
    "print (\"  \".join(jieba.analyse.extract_tags(content_S_str, topK=5, withWeight=False)))#3输出前五个关键词"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023*\"我国\" + 0.023*\"汽车\" + 0.020*\"价格\" + 0.012*\"中\" + 0.010*\"出售\"\n"
     ]
    }
   ],
   "source": [
    "# LDA模型建立\n",
    "\n",
    "## 训练集\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim\n",
    "#做映射，相当于词袋\n",
    "dictionary = corpora.Dictionary(contents_clean) ##格式要求：list of list形式，分词好的的整个语料\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in contents_clean]  #语料\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=20) #类似Kmeans自己指定K值\n",
    "print (lda.print_topic(1, topn=5)) ##第一个主题，关键词5个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022*\"健康\" + 0.020*\"公司\" + 0.019*\"中国\" + 0.014*\"个人\" + 0.011*\"防疫\"\n",
      "0.023*\"我国\" + 0.023*\"汽车\" + 0.020*\"价格\" + 0.012*\"中\" + 0.010*\"出售\"\n",
      "0.045*\"11\" + 0.036*\"月\" + 0.025*\"同比\" + 0.024*\"专家\" + 0.020*\"银行\"\n",
      "0.049*\"公司\" + 0.022*\"经济\" + 0.020*\"集团\" + 0.019*\"中央\" + 0.015*\"元\"\n",
      "0.020*\"三大\" + 0.019*\"发展\" + 0.016*\"服务\" + 0.015*\"数据\" + 0.013*\"50\"\n",
      "0.029*\"资金\" + 0.022*\"公司\" + 0.016*\"增\" + 0.015*\"出海\" + 0.012*\"措施\"\n",
      "0.038*\"增长\" + 0.018*\"科学\" + 0.017*\"加快\" + 0.015*\"收\" + 0.014*\"月\"\n",
      "0.040*\"企业\" + 0.015*\"部门\" + 0.013*\"逾\" + 0.011*\"两年\" + 0.011*\"20\"\n",
      "0.044*\"月\" + 0.025*\"12\" + 0.021*\"多地\" + 0.017*\"金融\" + 0.017*\"11\"\n",
      "0.045*\"消费\" + 0.018*\"2023\" + 0.014*\"违规\" + 0.013*\"年\" + 0.012*\"铁路\"\n",
      "0.021*\"中国\" + 0.020*\"预期\" + 0.019*\"约\" + 0.018*\"新冠\" + 0.015*\"病毒\"\n",
      "0.023*\"解读\" + 0.022*\"拟\" + 0.019*\"经济\" + 0.019*\"用于\" + 0.018*\"新\"\n",
      "0.141*\"公司\" + 0.016*\"月\" + 0.014*\"明年\" + 0.014*\"监管\" + 0.013*\"11\"\n",
      "0.042*\"工作\" + 0.026*\"人民币\" + 0.023*\"经济\" + 0.022*\"会议\" + 0.015*\"涨幅\"\n",
      "0.021*\"恢复\" + 0.015*\"新冠\" + 0.012*\"5\" + 0.012*\"逾\" + 0.010*\"8\"\n",
      "0.046*\"市场\" + 0.024*\"科学\" + 0.016*\"银行\" + 0.014*\"首个\" + 0.012*\"项目\"\n",
      "0.020*\"科学家\" + 0.016*\"贷款\" + 0.015*\"国内\" + 0.013*\"称\" + 0.013*\"数据\"\n",
      "0.027*\"经济\" + 0.023*\"订单\" + 0.016*\"美元\" + 0.015*\"明年\" + 0.014*\"预计\"\n",
      "0.039*\"公司\" + 0.014*\"不\" + 0.013*\"年\" + 0.013*\"上海\" + 0.013*\"项目\"\n",
      "0.026*\"核酸\" + 0.014*\"多家\" + 0.011*\"不再\" + 0.011*\"北京\" + 0.011*\"相关\"\n"
     ]
    }
   ],
   "source": [
    "# 输出20个主题的的关键词和权重\n",
    "\n",
    "## 训练集\n",
    "for topic in lda.print_topics(num_topics=20, num_words=5):\n",
    "    print (topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         contents_clean label\n",
      "4995  [北京, 第四, 批次, 6, 宗, 住宅, 用地, 收金, 135, 亿元, 热度, 达到...    财经\n",
      "4996  [杭州, 第四, 批次, 供地, 8, 宗, 宅地, 收金, 98.9, 亿元, 3, 宗,...    财经\n",
      "4997  [独家, 知情人, 谈张, 核子, 核酸, 生意, 深圳, 坐, 拥带, 停机坪, 别墅, ...    财经\n",
      "4998  [放量, 大涨, 沪, 指, 收复, 60, 日, 均线, 反弹, 持续性, 挑战, 半年线...    财经\n",
      "4999  [三天, 涨, 超, 30%, 翰宇, 药业, 预防, 新冠, 多肽, 鼻, 喷, 已, 紧...    财经\n",
      "                                         contents_clean label\n",
      "4995  [北京, 第四, 批次, 6, 宗, 住宅, 用地, 收金, 135, 亿元, 热度, 达到...    财经\n",
      "4996  [杭州, 第四, 批次, 供地, 8, 宗, 宅地, 收金, 98.9, 亿元, 3, 宗,...    财经\n",
      "4997  [独家, 知情人, 谈张, 核子, 核酸, 生意, 深圳, 坐, 拥带, 停机坪, 别墅, ...    财经\n",
      "4998  [放量, 大涨, 沪, 指, 收复, 60, 日, 均线, 反弹, 持续性, 挑战, 半年线...    财经\n",
      "4999  [三天, 涨, 超, 30%, 翰宇, 药业, 预防, 新冠, 多肽, 鼻, 喷, 已, 紧...    财经\n",
      "['国际' '思想' '时事' '科技' '财经']\n"
     ]
    }
   ],
   "source": [
    "# 数据转化\n",
    "\n",
    "## 训练集\n",
    "df_train = pd.DataFrame({'contents_clean':contents_clean,'label':df_news['label']})\n",
    "print(df_train.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 查看训练集的数据和不同的label\n",
    "print(df_train.tail())\n",
    "print(df_train.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                      contents_clean  label\n0  [持续, 追踪, 俄, 再度, 炮击, 赫尔松, 泽, 连斯基, 呼吁, 西方, 加强, 乌...      0\n1    [COP15, 专访, 穿, 汉服, 中国, 代表团, 成员, 讲述, 谈判, 背后, 故事]      0\n2     [泰国, 一艘, 军舰, 沉没, 搜救, 队, 正在, 寻找, 33, 名, 失踪, 船员]      0\n3    [圆桌, 威, 斯特伐, 利亚, 体系, 从未, 退场, 俄乌, 冲突, 下, 欧洲, 之变]      0\n4  [法国, 败北, 马克, 龙, 表态, 决赛, 不是, 提前, 写, 好, 剧本, 希望, ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contents_clean</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[持续, 追踪, 俄, 再度, 炮击, 赫尔松, 泽, 连斯基, 呼吁, 西方, 加强, 乌...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[COP15, 专访, 穿, 汉服, 中国, 代表团, 成员, 讲述, 谈判, 背后, 故事]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[泰国, 一艘, 军舰, 沉没, 搜救, 队, 正在, 寻找, 33, 名, 失踪, 船员]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[圆桌, 威, 斯特伐, 利亚, 体系, 从未, 退场, 俄乌, 冲突, 下, 欧洲, 之变]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[法国, 败北, 马克, 龙, 表态, 决赛, 不是, 提前, 写, 好, 剧本, 希望, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对数据标签进行map映射\n",
    "label_mapping = {\"国际\": 0, \"思想\": 1, \"时事\": 2, \"科技\": 3, \"财经\":4}\n",
    "df_train['label'] = df_train['label'].map(label_mapping) ##变换label\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train['contents_clean'].values, df_train['label'].values, test_size=0.2, random_state=1, shuffle=True,stratify=df_train['label'].values)\n",
    "\n",
    "words = []\n",
    "for line_index in range(len(x_train)):  \n",
    "    try:\n",
    "        #x_train[line_index][word_index] = str(x_train[line_index][word_index])\n",
    "        words.append(' '.join(x_train[line_index]))\n",
    "    except:\n",
    "        print (line_index)\n",
    "     \n",
    "     \n",
    "test_words = []\n",
    "for line_index in range(len(x_test)):\n",
    "    try:\n",
    "        #x_train[line_index][word_index] = str(x_train[line_index][word_index])\n",
    "        test_words.append(' '.join(x_test[line_index]))\n",
    "    except:\n",
    "         print (line_index)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.855"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "tdidf = TFIDF()\n",
    "\n",
    "tdidf = tdidf.fit(words)\n",
    "x_train = tdidf.transform(words).toarray()\n",
    "x_test = tdidf.transform(test_words).toarray()\n",
    "\n",
    "model = CalibratedClassifierCV(MultinomialNB(), cv=2, method='isotonic')\n",
    "model = model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "proba = model.predict_proba(x_test)\n",
    "\n",
    "score = model.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确度: 0.9965\n",
      "测试集的准确度: 0.873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import  SVC\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "tdidf = TFIDF()\n",
    "\n",
    "tdidf = tdidf.fit(words)\n",
    "x_train = tdidf.transform(words)\n",
    "x_test = tdidf.transform(test_words)\n",
    "\n",
    "# model = CalibratedClassifierCV(MultinomialNB(), cv=2, method='isotonic')\n",
    "model = SVC(C=0.8)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "train_pred = model.predict(x_train)\n",
    "test_pred = model.predict(x_test)\n",
    "print(\"训练集的准确度:\",acc(y_train,train_pred))\n",
    "print(\"测试集的准确度:\",acc(y_test,test_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确度: 0.99725\n",
      "测试集的准确度: 0.875\n"
     ]
    }
   ],
   "source": [
    "model = CalibratedClassifierCV(SVC(C=0.8), cv=5, method='isotonic')\n",
    "model.fit(x_train,y_train)\n",
    "train_pred = model.predict(x_train)\n",
    "test_pred = model.predict(x_test)\n",
    "print(\"训练集的准确度:\",acc(y_train,train_pred))\n",
    "print(\"测试集的准确度:\",acc(y_test,test_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}